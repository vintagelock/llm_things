# llm_things


https://ollama.ai/  -  Ollama - Run LLM locally
